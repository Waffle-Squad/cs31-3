{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model_saving_and_loading.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OS4TbyC4K5KD"
      },
      "source": [
        "# keras相关包\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img\n",
        "\n",
        "import random\n",
        "# sklearn相关包\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.feature_extraction.image import extract_patches_2d\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from imutils import paths\n",
        "import progressbar\n",
        "\n",
        "# 作图\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "#Basic Tool\n",
        "import pandas as pd\n",
        "import sys\n",
        "import io"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJgKx-M4EnLN"
      },
      "source": [
        "# Data Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzrPbENqMzeg",
        "outputId": "b633fe8b-2d62-4fcf-ff69-52b59f96dc13"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIqPhuFlElRS"
      },
      "source": [
        "#设置随机种子\n",
        "np.random.seed(161)\n",
        "\n",
        "from keras.datasets import cifar10"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oII5VMJ9EsAP"
      },
      "source": [
        "# PreProcessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRGua98MdYEd"
      },
      "source": [
        "###The normalized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjvD7tBdM4bF"
      },
      "source": [
        "#读取数据集\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "#归一化\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0XSF2grOJv_"
      },
      "source": [
        "def imbalanceData(__format,X_train,y_train):\n",
        "   \"\"\"\n",
        "   __format：The imbalance want to input\n",
        "   X_train:Train Set\n",
        "   y_train:Test Set\n",
        "   \"\"\"\n",
        "   train_classes, train_class_counts=np.unique(y_train, return_counts=True)\n",
        "   nb_train_classes = len(train_classes)\n",
        "   class_indices = [np.where(y_train == i)[0] for i in range(nb_train_classes)]\n",
        "   imbal_class_indices = [class_idx[:class_count] for class_idx, class_count in zip(class_indices, __format)]\n",
        "   imbal_class_indices = np.hstack(imbal_class_indices)\n",
        "   y = y_train[imbal_class_indices]\n",
        "   X = x_train[imbal_class_indices]  \n",
        "   return X,y"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4_5ecHifMPt"
      },
      "source": [
        "imbal_class_counts=[500,1000]*5 #you can use the format such:[500,1000]*5 [100,200,300,400,500,...,1000]\n",
        "x_train,y_train=imbalanceData(imbal_class_counts,x_train,y_train)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0mF1tDefEP4"
      },
      "source": [
        "### One-Hot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWk9wHlYMm53"
      },
      "source": [
        ""
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOlJrzR-M4i-"
      },
      "source": [
        "# Y 热编码\n",
        "y_train_oh = to_categorical(y_train)\n",
        "y_test_oh = to_categorical(y_test)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3peE2qg5wDVL"
      },
      "source": [
        "Regarding the saving and loading of models, there are generally three scenarios in Keras: save the entire model; only save the structure of the model;only save the weight of the model.\n",
        "Based on the models of the previous few weeks, write the code for saving and loading the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jz8GnETbEWBz"
      },
      "source": [
        "# ResNet-50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_MLXJiZNCZW"
      },
      "source": [
        "# 加载不包含top层的ResNet50作为baseModel\n",
        "baseModel = ResNet50(weights=\"imagenet\", include_top=False, input_tensor=Input(shape=(32, 32, 3)))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlKJFEqqNCcI"
      },
      "source": [
        "def headmodel(baseModel):\n",
        "    # 在baseModel基础上添加新的层\n",
        "    headModel = baseModel.output\n",
        "    \n",
        "    # 新的 top 层\n",
        "    headModel = Flatten()(headModel)\n",
        "    headModel = Dense(10, activation=\"softmax\")(headModel)\n",
        "    return headModel"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qEKkivaNCex"
      },
      "source": [
        "headModel = headmodel(baseModel)\n",
        "model = Model(inputs=baseModel.input, outputs=headModel)\n",
        "aug00 = ImageDataGenerator(rotation_range=30,\n",
        "                         width_shift_range=0.1,\n",
        "                         height_shift_range=0.1, \n",
        "                         shear_range=0.2, \n",
        "                         zoom_range=0.2,\n",
        "                         horizontal_flip=True,\n",
        "                         fill_mode=\"nearest\")"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_reHWm0NIHI"
      },
      "source": [
        ""
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xO4vW_BxFa8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNN5UkvbNIKH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e49c963-59ce-4d51-e729-6fef921aa039"
      },
      "source": [
        "# 保存模型快照的回调函数\n",
        "modelname = \"cifar10-resnet50-weights-{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(modelname, monitor=\"val_loss\", mode=\"min\", save_best_only=True)\n",
        "# 冻结住baseModel所有层的参数不学习\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "# 编译\n",
        "sgd = SGD(lr=0.01, decay=0.01 / 20, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,metrics=[\"accuracy\"])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joPZr2pENISB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fe1d7b9-0f23-4da6-ec68-140b2ade6cac"
      },
      "source": [
        "H = model.fit_generator(aug00.flow(x_train, y_train_oh, batch_size=32),\n",
        "                        validation_data=(x_test, y_test_oh),\n",
        "                        callbacks=[checkpoint],\n",
        "                        steps_per_epoch=len(x_train) // 32,\n",
        "                        epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "234/234 [==============================] - 99s 390ms/step - loss: 45.3566 - accuracy: 0.1149 - val_loss: 50.2283 - val_accuracy: 0.1006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/20\n",
            "234/234 [==============================] - 89s 383ms/step - loss: 34.4128 - accuracy: 0.1375 - val_loss: 29.5899 - val_accuracy: 0.1281\n",
            "Epoch 3/20\n",
            "234/234 [==============================] - 90s 387ms/step - loss: 27.3288 - accuracy: 0.1417 - val_loss: 20.0455 - val_accuracy: 0.1793\n",
            "Epoch 4/20\n",
            "234/234 [==============================] - 90s 386ms/step - loss: 19.2770 - accuracy: 0.1623 - val_loss: 15.2349 - val_accuracy: 0.1296\n",
            "Epoch 5/20\n",
            " 78/234 [=========>....................] - ETA: 28s - loss: 15.0815 - accuracy: 0.1843"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8blj1awzNChl"
      },
      "source": [
        "# 绘制loss和accuracy曲线\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hKjVomkbrNA"
      },
      "source": [
        "#F1-Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ribwqCNSZb"
      },
      "source": [
        "# Classified evaluation report\n",
        "preds = model.predict(x_test, batch_size=32)\n",
        "print(classification_report(y_test_oh.argmax(axis=1),preds.argmax(axis=1), digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgG-RliGIMJa"
      },
      "source": [
        "final_report = classification_report(y_test_oh.argmax(axis=1),preds.argmax(axis=1), digits=4)\n",
        "report_pd = pd.read_csv(io.StringIO(final_report), delim_whitespace=True, error_bad_lines=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GZR9iF1IxUG"
      },
      "source": [
        "report_re = report_pd[:10]\n",
        "report_re = report_re.reset_index()\n",
        "report_re = report_re[[\"index\", \"f1-score\"]]\n",
        "report_re.columns=['class_name','f1_score']\n",
        "#1-F1 score used for uodating the sample size \n",
        "report_re['1-f1_score'] = 1-report_re['f1_score']\n",
        "ds_sum = report_re['1-f1_score'].sum() \n",
        "report_re[\"class_weight\"] = report_re[\"1-f1_score\"]/ds_sum\n",
        "report_re[\"re_class_counts\"] = (report_re[\"1-f1_score\"]/ds_sum)*len(x_train)\n",
        "report_re[\"row_distribution\"] = pd.DataFrame(imbal_class_counts)\n",
        "report_re['tt'] = report_re['re_class_counts'] - report_re['row_distribution']\n",
        "report_re.loc[report_re[\"tt\"]<0,\"tt\"] = report_re[\"re_class_counts\"]\n",
        "report_re002 = report_re[[\"class_name\",\"class_weight\",\"re_class_counts\",\"row_distribution\",\"tt\"]]\n",
        "report_re002[\"tt\"] = round(report_re002[\"tt\"])\n",
        "report_re002.columns=['class_name',\"class_weight\",\"re_class_counts\",\"row_distribution\",\"update_num\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOJEawWSOIBw"
      },
      "source": [
        "def choosingImages(x_train,y_train):\n",
        "  \"\"\"\n",
        "  x_train:Train Data\n",
        "  y_train:Test Data\n",
        "  \"\"\"\n",
        "  c_X_train=[]\n",
        "  for i in range(10):\n",
        "    print(i)\n",
        "    class_indices_=[np.where(y_train == i)[0]]\n",
        "    x_train_ = x_train[class_indices_]\n",
        "    c_X_train.append(x_train_)\n",
        "  return c_X_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tucj_HJapnH"
      },
      "source": [
        "X_train_list=choosingImages(x_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYTab5bShIBx"
      },
      "source": [
        "def data_augmentation(img, number):\n",
        "  image = np.expand_dims(img, axis=0)\n",
        "  # Instantiate the image generator class to specify some common image augmentation parameters\n",
        "  aug = ImageDataGenerator(rotation_range=30,\n",
        "                width_shift_range=0.1,\n",
        "                height_shift_range=0.1, \n",
        "                shear_range=0.2, \n",
        "                zoom_range=0.2,\n",
        "                horizontal_flip=True,\n",
        "                fill_mode=\"nearest\")\n",
        "    \n",
        "  imageGen = aug.flow(image, batch_size=1)\n",
        "  # aug.flow??\n",
        "\n",
        "  total = 0\n",
        "  imglist = []\n",
        "  for x in imageGen:\n",
        "    total += 1\n",
        "    imglist.append(x)\n",
        "    if total == number:\n",
        "      break\n",
        "\n",
        "  # imgback = np.array(imglist)\n",
        "  return imglist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLfzGh4aboh1"
      },
      "source": [
        "def img_add(x_train_i, num):\n",
        "  img_list = []\n",
        "  for image in x_train_i:\n",
        "    img_list_i = data_augmentation(image, 20)\n",
        "    img_list.extend(img_list_i)\n",
        "  \n",
        "  imgback = random.sample(img_list, num)\n",
        "  imgback = np.array(imgback)\n",
        "  final_x_train_i = np.vstack((x_train_i,imgback.squeeze()))\n",
        "  return final_x_train_i\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6EjYxMEvpOW"
      },
      "source": [
        "len(X_train_list[])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V20pXR1iqDf7"
      },
      "source": [
        "ds_change_0 = img_add(X_train_list[0], 188)\n",
        "ds_change_1 = np.array(random.sample(list(X_train_list[1]), 502))\n",
        "ds_change_2 = img_add(X_train_list[2], 345)\n",
        "ds_change_3 = np.array(random.sample(list(X_train_list[3]), 886))\n",
        "ds_change_4 = img_add(X_train_list[4], 362)\n",
        "ds_change_5 = np.array(random.sample(list(X_train_list[5]), 858))\n",
        "ds_change_6 = img_add(X_train_list[6], 359)\n",
        "ds_change_7 = np.array(random.sample(list(X_train_list[7]), 665))\n",
        "ds_change_8 = np.array(random.sample(list(X_train_list[8]), 477))\n",
        "ds_change_9 = np.array(random.sample(list(X_train_list[9]), 857))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1fJXkTfpql5"
      },
      "source": [
        "# x_train_new = np.vstack((ds_change_0,ds_change_1))\n",
        "# x_train_new = np.vstack((x_train_new,ds_change_2))\n",
        "# x_train_new = np.vstack((x_train_new,ds_change_3))\n",
        "# x_train_new = np.vstack((x_train_new,ds_change_4))\n",
        "# x_train_new = np.vstack((x_train_new,ds_change_5))\n",
        "# x_train_new = np.vstack((x_train_new,ds_change_6))\n",
        "# x_train_new = np.vstack((x_train_new,ds_change_7))\n",
        "# x_train_new = np.vstack((x_train_new,ds_change_8))\n",
        "# x_train_new = np.vstack((x_train_new,ds_change_9))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGbAjIW05rNH"
      },
      "source": [
        "def new_array(row,nmb):\n",
        "  new_arr = np.zeros((row,1))\n",
        "  for i in range(row):\n",
        "    new_arr[i] = np.array([nmb])\n",
        "  return new_arr\n",
        "\n",
        "def change_y(update__):\n",
        "  \"\"\"\n",
        "  update_list:The update size relate to F1-score\n",
        "  \"\"\"\n",
        "  update_list=[]\n",
        "  for i in range(len(update__)):\n",
        "    _y=new_array(update__[i],i)\n",
        "    update_list.append(_y)\n",
        "  y_train_new = np.vstack((update_list[0],update_list[1]))\n",
        "  for j in range(len(update_list)):\n",
        "     if(j>=2):\n",
        "      y_train_new = np.vstack((y_train_new,update_list[j]))\n",
        "\n",
        "  #One-hot coding\n",
        "  y_train_new_oh = to_categorical(y_train_new)\n",
        "\n",
        "  return y_train_new_oh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ob03RZ8f_57"
      },
      "source": [
        "y_train_new_oh = change_y([688,502,845,886,862,858,859,665,477,857])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cN6I3yiQ-eEK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoDzlyyMNScd"
      },
      "source": [
        "# 允许baseModel所有层的参数都可学习\n",
        "for layer in baseModel.layers:\n",
        "    layer.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yK855vbXNSfE"
      },
      "source": [
        "# 保存模型快照的回调函数\n",
        "modelname = \"final_cifar10-resnet50-weights-{epoch:03d}-{val_loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(modelname, monitor=\"val_loss\", mode=\"min\", save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2RLTapINSh7"
      },
      "source": [
        "# 编译\n",
        "sgd = SGD(lr=0.001, decay=0.001 / 20, momentum=0.9, nesterov=True)\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=sgd,metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biEXOASvNSkj"
      },
      "source": [
        "H = model.fit_generator(aug00.flow(x_train_new, y_train_new_oh, batch_size=32),\n",
        "                        validation_data=(x_test, y_test_oh),\n",
        "                        callbacks=[checkpoint],\n",
        "                        steps_per_epoch=len(x_train) // 32,\n",
        "                        epochs=20)\n",
        "\n",
        "# H = model.fit(x_train_new, y_train_new_oh, batch_size=32,\n",
        "#                         validation_data=(x_test, y_test_oh),\n",
        "#                         callbacks=[checkpoint],\n",
        "#                         epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuXd_CYoNvMH"
      },
      "source": [
        "\n",
        "# 绘制loss和accuracy曲线\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1grp-nqNvO6"
      },
      "source": [
        "# 分类评估报告\n",
        "preds = model.predict(x_test, batch_size=32)\n",
        "print(classification_report(y_test_oh.argmax(axis=1),preds.argmax(axis=1), digits=4))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJqDT8tpNvRx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}